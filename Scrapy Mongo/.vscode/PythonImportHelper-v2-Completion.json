[
    {
        "label": "scrapy",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "scrapy",
        "description": "scrapy",
        "detail": "scrapy",
        "documentation": {}
    },
    {
        "label": "signals",
        "importPath": "scrapy",
        "description": "scrapy",
        "isExtraImport": true,
        "detail": "scrapy",
        "documentation": {}
    },
    {
        "label": "Path",
        "importPath": "pathlib",
        "description": "pathlib",
        "isExtraImport": true,
        "detail": "pathlib",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "MongoClient",
        "importPath": "pymongo",
        "description": "pymongo",
        "isExtraImport": true,
        "detail": "pymongo",
        "documentation": {}
    },
    {
        "label": "datetime",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "datetime",
        "description": "datetime",
        "detail": "datetime",
        "documentation": {}
    },
    {
        "label": "is_item",
        "importPath": "itemadapter",
        "description": "itemadapter",
        "isExtraImport": true,
        "detail": "itemadapter",
        "documentation": {}
    },
    {
        "label": "ItemAdapter",
        "importPath": "itemadapter",
        "description": "itemadapter",
        "isExtraImport": true,
        "detail": "itemadapter",
        "documentation": {}
    },
    {
        "label": "ItemAdapter",
        "importPath": "itemadapter",
        "description": "itemadapter",
        "isExtraImport": true,
        "detail": "itemadapter",
        "documentation": {}
    },
    {
        "label": "sys",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "sys",
        "description": "sys",
        "detail": "sys",
        "documentation": {}
    },
    {
        "label": "json",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "json",
        "description": "json",
        "detail": "json",
        "documentation": {}
    },
    {
        "label": "argparse",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "argparse",
        "description": "argparse",
        "detail": "argparse",
        "documentation": {}
    },
    {
        "label": "pformat",
        "importPath": "pprint",
        "description": "pprint",
        "isExtraImport": true,
        "detail": "pprint",
        "documentation": {}
    },
    {
        "label": "jmespath",
        "kind": 6,
        "isExtraImport": true,
        "importPath": "jmespath",
        "description": "jmespath",
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "exceptions",
        "importPath": "jmespath",
        "description": "jmespath",
        "isExtraImport": true,
        "detail": "jmespath",
        "documentation": {}
    },
    {
        "label": "BooksSpider",
        "kind": 6,
        "importPath": "bookdata.bookdata.spiders.books",
        "description": "bookdata.bookdata.spiders.books",
        "peekOfCode": "class BooksSpider(scrapy.Spider):\n    name = \"books\"\n    allowed_domains = [\"toscrape.com\"]\n    start_urls = [\"https://toscrape.com\"]\n    def start_requests(self):\n        urls = [\n            \"https://books.toscrape.com/catalogue/category/books/travel_2/index.html\",\n            \"https://books.toscrape.com/catalogue/category/books/mystery_3/index.html\",\n        ]\n        for url in urls:",
        "detail": "bookdata.bookdata.spiders.books",
        "documentation": {}
    },
    {
        "label": "insertToDb",
        "kind": 2,
        "importPath": "bookdata.bookdata.spiders.books",
        "description": "bookdata.bookdata.spiders.books",
        "peekOfCode": "def insertToDb(page, title, rating, image, price, inStock):\n    collection = db[page]\n    doc = {\n        \"title\" : title,\n        \"rating\" : rating,\n        \"image\" : image,\n        \"price\" : price,\n        \"inStock\" : inStock,\n        \"date\": datetime.datetime.now(tz=datetime.timezone.utc),\n    }",
        "detail": "bookdata.bookdata.spiders.books",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "bookdata.bookdata.spiders.books",
        "description": "bookdata.bookdata.spiders.books",
        "peekOfCode": "client = MongoClient(\"mongodb+srv://test:AkibNayan2@cluster0.dt5i7bu.mongodb.net/\")\ndb = client.booksDataScrape\ndef insertToDb(page, title, rating, image, price, inStock):\n    collection = db[page]\n    doc = {\n        \"title\" : title,\n        \"rating\" : rating,\n        \"image\" : image,\n        \"price\" : price,\n        \"inStock\" : inStock,",
        "detail": "bookdata.bookdata.spiders.books",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "bookdata.bookdata.spiders.books",
        "description": "bookdata.bookdata.spiders.books",
        "peekOfCode": "db = client.booksDataScrape\ndef insertToDb(page, title, rating, image, price, inStock):\n    collection = db[page]\n    doc = {\n        \"title\" : title,\n        \"rating\" : rating,\n        \"image\" : image,\n        \"price\" : price,\n        \"inStock\" : inStock,\n        \"date\": datetime.datetime.now(tz=datetime.timezone.utc),",
        "detail": "bookdata.bookdata.spiders.books",
        "documentation": {}
    },
    {
        "label": "BookdataItem",
        "kind": 6,
        "importPath": "bookdata.bookdata.items",
        "description": "bookdata.bookdata.items",
        "peekOfCode": "class BookdataItem(scrapy.Item):\n    # define the fields for your item here like:\n    # name = scrapy.Field()\n    pass",
        "detail": "bookdata.bookdata.items",
        "documentation": {}
    },
    {
        "label": "BookdataSpiderMiddleware",
        "kind": 6,
        "importPath": "bookdata.bookdata.middlewares",
        "description": "bookdata.bookdata.middlewares",
        "peekOfCode": "class BookdataSpiderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the spider middleware does not modify the\n    # passed objects.\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s",
        "detail": "bookdata.bookdata.middlewares",
        "documentation": {}
    },
    {
        "label": "BookdataDownloaderMiddleware",
        "kind": 6,
        "importPath": "bookdata.bookdata.middlewares",
        "description": "bookdata.bookdata.middlewares",
        "peekOfCode": "class BookdataDownloaderMiddleware:\n    # Not all methods need to be defined. If a method is not defined,\n    # scrapy acts as if the downloader middleware does not modify the\n    # passed objects.\n    @classmethod\n    def from_crawler(cls, crawler):\n        # This method is used by Scrapy to create your spiders.\n        s = cls()\n        crawler.signals.connect(s.spider_opened, signal=signals.spider_opened)\n        return s",
        "detail": "bookdata.bookdata.middlewares",
        "documentation": {}
    },
    {
        "label": "BookdataPipeline",
        "kind": 6,
        "importPath": "bookdata.bookdata.pipelines",
        "description": "bookdata.bookdata.pipelines",
        "peekOfCode": "class BookdataPipeline:\n    def process_item(self, item, spider):\n        return item",
        "detail": "bookdata.bookdata.pipelines",
        "documentation": {}
    },
    {
        "label": "BOT_NAME",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "BOT_NAME = \"bookdata\"\nSPIDER_MODULES = [\"bookdata.spiders\"]\nNEWSPIDER_MODULE = \"bookdata.spiders\"\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = \"bookdata (+http://www.yourdomain.com)\"\n# Obey robots.txt rules\nROBOTSTXT_OBEY = True\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n# Configure a delay for requests for the same website (default: 0)",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "SPIDER_MODULES",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "SPIDER_MODULES = [\"bookdata.spiders\"]\nNEWSPIDER_MODULE = \"bookdata.spiders\"\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = \"bookdata (+http://www.yourdomain.com)\"\n# Obey robots.txt rules\nROBOTSTXT_OBEY = True\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "NEWSPIDER_MODULE",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "NEWSPIDER_MODULE = \"bookdata.spiders\"\n# Crawl responsibly by identifying yourself (and your website) on the user-agent\n#USER_AGENT = \"bookdata (+http://www.yourdomain.com)\"\n# Obey robots.txt rules\nROBOTSTXT_OBEY = True\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#USER_AGENT",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#USER_AGENT = \"bookdata (+http://www.yourdomain.com)\"\n# Obey robots.txt rules\nROBOTSTXT_OBEY = True\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "ROBOTSTXT_OBEY",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "ROBOTSTXT_OBEY = True\n# Configure maximum concurrent requests performed by Scrapy (default: 16)\n#CONCURRENT_REQUESTS = 32\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#CONCURRENT_REQUESTS",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#CONCURRENT_REQUESTS = 32\n# Configure a delay for requests for the same website (default: 0)\n# See https://docs.scrapy.org/en/latest/topics/settings.html#download-delay\n# See also autothrottle settings and docs\n#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#DOWNLOAD_DELAY",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#DOWNLOAD_DELAY = 3\n# The download delay setting will honor only one of:\n#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#CONCURRENT_REQUESTS_PER_DOMAIN",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#CONCURRENT_REQUESTS_PER_DOMAIN = 16\n#CONCURRENT_REQUESTS_PER_IP = 16\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#CONCURRENT_REQUESTS_PER_IP",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#CONCURRENT_REQUESTS_PER_IP = 16\n# Disable cookies (enabled by default)\n#COOKIES_ENABLED = False\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#COOKIES_ENABLED",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#COOKIES_ENABLED = False\n# Disable Telnet Console (enabled by default)\n#TELNETCONSOLE_ENABLED = False\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}\n# Enable or disable spider middlewares\n# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#TELNETCONSOLE_ENABLED",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#TELNETCONSOLE_ENABLED = False\n# Override the default request headers:\n#DEFAULT_REQUEST_HEADERS = {\n#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}\n# Enable or disable spider middlewares\n# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    \"bookdata.middlewares.BookdataSpiderMiddleware\": 543,",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#DEFAULT_REQUEST_HEADERS",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#DEFAULT_REQUEST_HEADERS = {\n#    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n#    \"Accept-Language\": \"en\",\n#}\n# Enable or disable spider middlewares\n# See https://docs.scrapy.org/en/latest/topics/spider-middleware.html\n#SPIDER_MIDDLEWARES = {\n#    \"bookdata.middlewares.BookdataSpiderMiddleware\": 543,\n#}\n# Enable or disable downloader middlewares",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#SPIDER_MIDDLEWARES",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#SPIDER_MIDDLEWARES = {\n#    \"bookdata.middlewares.BookdataSpiderMiddleware\": 543,\n#}\n# Enable or disable downloader middlewares\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html\n#DOWNLOADER_MIDDLEWARES = {\n#    \"bookdata.middlewares.BookdataDownloaderMiddleware\": 543,\n#}\n# Enable or disable extensions\n# See https://docs.scrapy.org/en/latest/topics/extensions.html",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#DOWNLOADER_MIDDLEWARES",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#DOWNLOADER_MIDDLEWARES = {\n#    \"bookdata.middlewares.BookdataDownloaderMiddleware\": 543,\n#}\n# Enable or disable extensions\n# See https://docs.scrapy.org/en/latest/topics/extensions.html\n#EXTENSIONS = {\n#    \"scrapy.extensions.telnet.TelnetConsole\": None,\n#}\n# Configure item pipelines\n# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#EXTENSIONS",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#EXTENSIONS = {\n#    \"scrapy.extensions.telnet.TelnetConsole\": None,\n#}\n# Configure item pipelines\n# See https://docs.scrapy.org/en/latest/topics/item-pipeline.html\n#ITEM_PIPELINES = {\n#    \"bookdata.pipelines.BookdataPipeline\": 300,\n#}\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/autothrottle.html",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#ITEM_PIPELINES",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#ITEM_PIPELINES = {\n#    \"bookdata.pipelines.BookdataPipeline\": 300,\n#}\n# Enable and configure the AutoThrottle extension (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/autothrottle.html\n#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#AUTOTHROTTLE_ENABLED",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#AUTOTHROTTLE_ENABLED = True\n# The initial download delay\n#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#AUTOTHROTTLE_START_DELAY",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#AUTOTHROTTLE_START_DELAY = 5\n# The maximum download delay to be set in case of high latencies\n#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#AUTOTHROTTLE_MAX_DELAY",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#AUTOTHROTTLE_MAX_DELAY = 60\n# The average number of requests Scrapy should be sending in parallel to\n# each remote server\n#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#AUTOTHROTTLE_TARGET_CONCURRENCY",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#AUTOTHROTTLE_TARGET_CONCURRENCY = 1.0\n# Enable showing throttling stats for every response received:\n#AUTOTHROTTLE_DEBUG = False\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#AUTOTHROTTLE_DEBUG",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#AUTOTHROTTLE_DEBUG = False\n# Enable and configure HTTP caching (disabled by default)\n# See https://docs.scrapy.org/en/latest/topics/downloader-middleware.html#httpcache-middleware-settings\n#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#HTTPCACHE_ENABLED",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#HTTPCACHE_ENABLED = True\n#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#HTTPCACHE_EXPIRATION_SECS",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#HTTPCACHE_EXPIRATION_SECS = 0\n#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#HTTPCACHE_DIR",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#HTTPCACHE_DIR = \"httpcache\"\n#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#HTTPCACHE_IGNORE_HTTP_CODES",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#HTTPCACHE_IGNORE_HTTP_CODES = []\n#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "#HTTPCACHE_STORAGE",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "#HTTPCACHE_STORAGE = \"scrapy.extensions.httpcache.FilesystemCacheStorage\"\n# Set settings whose default value is deprecated to a future-proof value\nREQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "REQUEST_FINGERPRINTER_IMPLEMENTATION",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "REQUEST_FINGERPRINTER_IMPLEMENTATION = \"2.7\"\nTWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "TWISTED_REACTOR",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "TWISTED_REACTOR = \"twisted.internet.asyncioreactor.AsyncioSelectorReactor\"\nFEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "FEED_EXPORT_ENCODING",
        "kind": 5,
        "importPath": "bookdata.bookdata.settings",
        "description": "bookdata.bookdata.settings",
        "peekOfCode": "FEED_EXPORT_ENCODING = \"utf-8\"",
        "detail": "bookdata.bookdata.settings",
        "documentation": {}
    },
    {
        "label": "client",
        "kind": 5,
        "importPath": "bookdata.mongoscript",
        "description": "bookdata.mongoscript",
        "peekOfCode": "client = MongoClient(\"mongodb+srv://test:AkibNayan2@cluster0.dt5i7bu.mongodb.net/\")\ndb = client.scrapy\nposts = db.test_collection\ndoc = post = {\n    \"author\": \"Mike\",\n    \"text\": \"My first blog post!\",\n    \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\n    \"date\": datetime.datetime.now(tz=datetime.timezone.utc),\n}\npost_id = posts.insert_one(post).inserted_id",
        "detail": "bookdata.mongoscript",
        "documentation": {}
    },
    {
        "label": "db",
        "kind": 5,
        "importPath": "bookdata.mongoscript",
        "description": "bookdata.mongoscript",
        "peekOfCode": "db = client.scrapy\nposts = db.test_collection\ndoc = post = {\n    \"author\": \"Mike\",\n    \"text\": \"My first blog post!\",\n    \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\n    \"date\": datetime.datetime.now(tz=datetime.timezone.utc),\n}\npost_id = posts.insert_one(post).inserted_id\nprint(post_id)",
        "detail": "bookdata.mongoscript",
        "documentation": {}
    },
    {
        "label": "posts",
        "kind": 5,
        "importPath": "bookdata.mongoscript",
        "description": "bookdata.mongoscript",
        "peekOfCode": "posts = db.test_collection\ndoc = post = {\n    \"author\": \"Mike\",\n    \"text\": \"My first blog post!\",\n    \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\n    \"date\": datetime.datetime.now(tz=datetime.timezone.utc),\n}\npost_id = posts.insert_one(post).inserted_id\nprint(post_id)",
        "detail": "bookdata.mongoscript",
        "documentation": {}
    },
    {
        "label": "doc",
        "kind": 5,
        "importPath": "bookdata.mongoscript",
        "description": "bookdata.mongoscript",
        "peekOfCode": "doc = post = {\n    \"author\": \"Mike\",\n    \"text\": \"My first blog post!\",\n    \"tags\": [\"mongodb\", \"python\", \"pymongo\"],\n    \"date\": datetime.datetime.now(tz=datetime.timezone.utc),\n}\npost_id = posts.insert_one(post).inserted_id\nprint(post_id)",
        "detail": "bookdata.mongoscript",
        "documentation": {}
    },
    {
        "label": "post_id",
        "kind": 5,
        "importPath": "bookdata.mongoscript",
        "description": "bookdata.mongoscript",
        "peekOfCode": "post_id = posts.insert_one(post).inserted_id\nprint(post_id)",
        "detail": "bookdata.mongoscript",
        "documentation": {}
    },
    {
        "label": "main",
        "kind": 2,
        "importPath": "myenv.Scripts.jp",
        "description": "myenv.Scripts.jp",
        "peekOfCode": "def main():\n    parser = argparse.ArgumentParser()\n    parser.add_argument('expression')\n    parser.add_argument('-f', '--filename',\n                        help=('The filename containing the input data.  '\n                              'If a filename is not given then data is '\n                              'read from stdin.'))\n    parser.add_argument('--ast', action='store_true',\n                        help=('Pretty print the AST, do not search the data.'))\n    args = parser.parse_args()",
        "detail": "myenv.Scripts.jp",
        "documentation": {}
    }
]